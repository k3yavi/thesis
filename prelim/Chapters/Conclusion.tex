% Chapter 1

\chapter{Conclusion and Future Work} % Main chapter title
\label{conclusion} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
% \newcommand{\keyword}[1]{\textbf{#1}}
% \newcommand{\tabhead}[1]{\textbf{#1}}
% \newcommand{\code}[1]{\texttt{#1}}
% \newcommand{\file}[1]{\texttt{\bfseries#1}}
% \newcommand{\option}[1]{\texttt{\itshape#1}}

In this dissertation, we have presented effective computational methods to improve 
quantification of both bulk and dscRNA-seq data.

\section{Bulk RNA-seq}

In ~\Cref{rapmap} we have discussed the usefulness of our novel approach, \qm, 
for mapping RNA-seq reads. We show our efficient implemntation of \qm, in the 
form of \rapmap is fast, accurate and solves an important problem of read-mapping. 
In addition to that, we are reaching out to find other biological applications where 
\rapmap can be useful. In the following section, we discuss some of the applications, 
which we have worked on, or are currently working. 

\subsection{Supplementary Study}
\subsubsection{RapClust~\citep{srivastava2016accurate}}

De novo transcriptome assembly of non-model organisms is the first major step for many 
RNA-seq analysis tasks. Current methods for de novo assembly often report a large number 
of contiguous sequences (contigs), which may be fractured and incomplete sequences 
instead of full-length transcripts. Dealing with a large number of such contigs can 
slow and complicate downstream analysis. In this extention study, we present a method 
for clustering contigs from de novo transcriptome assemblies based upon the relationships 
exposed by multi-mapping sequencing fragments. Specifically, we cast the problem of 
clustering contigs as one of clustering a sparse graph that is induced by equivalence 
classes of fragments that map to subsets of the transcriptome. Leveraging recent developments 
in efficient read mapping and transcript quantification, we have developed RapClust, a tool 
implementing this approach that is capable of accurately clustering most large de novo 
transcriptomes in a matter of minutes, while simultaneously providing accurate estimates of 
expression for the resulting clusters. We compare RapClust against a number of tools commonly 
used for de novo transcriptome clustering. Using de novo assemblies of organisms for which 
reference genomes are available, we assess the accuracy of these different methods in terms of 
the quality of the resulting clusterings, and the concordance of differential expression tests 
with those based on ground truth clusters. We find that RapClust produces clusters of comparable 
or better quality than existing state-of-the-art approaches, and does so substantially faster. 
RapClust also confers a large benefit in terms of space usage, as it produces only succinct 
intermediate files - usually on the order of a few megabytes - even when processing hundreds 
of millions of reads.

\subsection{Future Study}
\subsubsection{Selective Alignment ~\citep{selaln}}

Since its introduction in 2008~\citep{lister,nagalakshmi,mortazavi}, transcriptome
profiling via RNA-seq has become a popular and widely-used technique to profile gene-
and transcript-level expression, and to identify and assemble novel transcripts.
Perhaps one of the most common uses of RNA-seq is to quantify gene expression,
often with the goal of subsequently performing differential expression analysis
on the gene abundance profiles. Due to improvements in RNA-seq quality and read
lengths, and also to significant improvements in the available quantification
methods, it has become increasingly common to perform quantification and
differential testing at the transcript level. Recently, there has been
considerable focus on developing very fast computational
methods~\citep{sailfish,kallisto,salmon,fleximer} for transcript abundance
estimation which obtain their speed, in part, by forgoing the traditional
prerequisite step of aligning the reads to the reference genome or
transcriptome. These methods have gained popularity due to their
markedly smaller computational requirements and their simplicity of use compared to more
traditional quantification ``pipelines'' that require alignment of the
sequencing reads to the genome or transcriptome, followed by the subsequent
processing of the resulting BAM file to obtain quantification estimates.

In various assessments on simulated data 
~\citep{kanitz2015comparative,germain2016rnaonthebench,zhang2017evaluation}, these lightweight 
methods have compared favorably to well-tested but much slower methods for
abundance estimation, like RSEM~\citep{rsem} coupled with alignment methods such
as Bowtie2~\citep{bowtie2}. However, assessments based primarily (or entirely)
upon simulated data often fail to capture important aspects of real experiments,
and similar performance among methods on such simulated datasets does not
necessarily generalize to experimental data. Popular methods for transcript
quantification~\citep{rnaskim,fleximer,salmon,kallisto,sailfish,rsem,vuong2018revisit} 
differ in many aspects, ranging from how they handle read mapping
and alignment, to the optimization algorithms they employ, to subtle differences
in their generative models or which biases they model and correct for. These
differences are often obscured when analyzing simulated data, since aspects of
experimental data that can lead to substantial divergence in quantification
estimates are not properly recapitulated in simulation.

We focus on one aspect of abundance estimation, namely the
effect of read mapping on the resulting transcript quantification estimates. We
show that differences in how reads are aligned or mapped can lead to
considerable differences in the predicted abundances. Specifically, we find that
lightweight mapping approaches\citep{sailfish,kallisto,rapmap,fleximer}, which
are generally highly concordant with traditional alignment approaches in
simulated data, can lead to quite different abundance estimates from
alignment-based methods in experimental data. These differences happen
across a large number of samples, but the magnitude of the differences can vary 
substantially from sample to sample. 
We also find that these differences are independent of the optimization procedure used to
infer transcript abundances, and are instead a result of the different mapping and
alignment approaches returning distinct, and sometimes even disjoint, mapping loci
for certain reads.

It is somewhat difficult to categorically specify which approaches produce more accurate 
estimates in experimental data, due to the absence of a ground truth. However,
we argue that the divergence of lightweight mapping approaches from traditional
alignment is usually the result of a failure of the greedy heuristics adopted by
lightweight approaches, which are explicitly adopted to maximize the speed of
such methods.

This further explores and provides evidence for a hypothesis, raised
in~\citet{selaln} and ~\citet{heraem}, that lightweight-mapping approaches may suffer from
spurious mappings leading to a decrease in the resulting quantification
accuracy. We also demonstrate that, even among alignment-based approaches,
non-trivial differences arise between quantifications based upon mapping to the
transcriptome (using Bowtie2~\citep{bowtie2}) and quantifications based upon
mapping to the genome and subsequently projecting these alignments into
transcriptomic coordinates (using STAR~\citep{star}).

Finally, we plan to introduce an improved mapping algorithm, selective alignment (\hsa),
that is designed to remain fast, while simultaneously eliminating many of the
mapping errors made by lightweight approaches. Our proposed method increases
both the sensitivity and specificity of fast read mapping. It relies upon
alignment scoring to help differentiate between mapping loci that would
otherwise be indistinguishable due to, for example, similar exact matches along
the reference. Our approach also determines when even the best mapping for a
read exhibits insufficient evidence that the read truly originated from the
locus in question, allowing it to avoid spurious mappings. We benchmark this
approach on both simulated data and a broad collection of experimental
RNA-seq samples, and demonstrate that it leads to considerably improved
concordance with the abundance estimates obtained via quantification following
traditional alignment to the transcriptome.

\section{Single cell RNA-seq}
In ~\cref{alevin}, we present a new end-to-end pipeline for performing gene-level 
quantification from \dscrnaseq. We show that, compared to other methods, \alevin achieves
a higher accuracy, in part because of considering a substantially larger number
of reads. Further, \alevin is considerably faster and uses less memory than
these other approaches. The optimizations used in \alevin makes it possible to 
efficiently process \dscrnaseq datasets in a reduced computational burden for 
processing and re-processing of \dscrnaseq data.

\subsection{Supplementary Study}
\subsubsection{Swish ~\citep{zhu2019nonparametric}}
A primary challenge in the analysis of RNA-seq data is to identify differentially 
expressed genes or transcripts while controlling for technical biases present in 
the observations. Ideally, a statistical testing procedure should incorporate 
information about the inherent uncertainty of the abundance estimates, whether at 
the gene or transcript level, that arise from quantification of abundance. Most 
popular methods for RNA-seq differential expression analysis fit a parametric model 
to the counts or scaled counts for each gene or transcript, and a subset of methods 
can incorporate information about the uncertainty of the counts. Previous work has 
shown that nonparametric models for RNA-seq differential expression may in some cases 
have better control of the false discovery rate, and adapt well to new data types 
without requiring reformulation of a parametric model. Existing nonparametric models 
do not take into account the inferential uncertainty of the observations, leading to 
an inflated false discovery rate, in particular at the transcript level. Here we 
propose a nonparametric model for differential expression analysis using inferential 
replicate counts, extending the existing SAMseq method to account for inferential 
uncertainty, batch effects, and sample pairing. We compare our method, 
"SAMseq With Inferential Samples Helps", or Swish, with popular differential 
expression analysis methods. Swish has improved control of the false discovery rate, 
in particular for transcripts with high inferential uncertainty. We apply Swish to 
a single-cell RNA-seq dataset, assessing sensitivity to recover DE genes between 
sub-populations of cells, and compare its performance to the Wilcoxon rank sum test.

\subsection{Future Study}
\subsubsection{Alevin 2.0}
In the future, we hope to further improve the benchmarking of accuracy
for single-cell quantification and barcode whitelisting approaches, as the
lack of standard benchmarks makes the assessment of new methods difficult. We
also hope to explore alternative cell barcode whitelisting and PUG resolution strategies --- for example,
adopting a generative model for PCR and sequencing error and seeking a maximum
likelihood rather than maximum parsimony-based resolution of the PUGs.
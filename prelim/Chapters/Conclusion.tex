% Chapter 1

\chapter{Conclusion and Future Work} % Main chapter title
\label{conclusion} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
% \newcommand{\keyword}[1]{\textbf{#1}}
% \newcommand{\tabhead}[1]{\textbf{#1}}
% \newcommand{\code}[1]{\texttt{#1}}
% \newcommand{\file}[1]{\texttt{\bfseries#1}}
% \newcommand{\option}[1]{\texttt{\itshape#1}}

In this dissertation, we have presented effective computational methods to improve 
quantification of both bulk and dscRNA-seq data.

\section{Bulk RNA-seq}

In ~\Cref{rapmap} we have discussed the usefulness of our novel approach, \qm, 
for mapping RNA-seq reads. We show our efficient implemntation of \qm, in the 
form of \rapmap is fast, accurate and solves an important problem of read-mapping. 
In addition to that, we are reaching out to find other biological applications where 
\rapmap can be useful. In the following section, we discuss some of the applications, 
which we have worked on, or are currently working. 

\subsection{Supplementary Study}
\subsubsection{RapClust~\citep{srivastava2016accurate}}

De novo transcriptome assembly of non-model organisms is the first major step for many 
RNA-seq analysis tasks. Current methods for de novo assembly often report a large number 
of contiguous sequences (contigs), which may be fractured and incomplete sequences 
instead of full-length transcripts. Dealing with a large number of such contigs can 
slow and complicate downstream analysis. In this extention study, we present a method 
for clustering contigs from de novo transcriptome assemblies based upon the relationships 
exposed by multi-mapping sequencing fragments. Specifically, we cast the problem of 
clustering contigs as one of clustering a sparse graph that is induced by equivalence 
classes of fragments that map to subsets of the transcriptome. Leveraging recent developments 
in efficient read mapping and transcript quantification, we have developed RapClust, a tool 
implementing this approach that is capable of accurately clustering most large de novo 
transcriptomes in a matter of minutes, while simultaneously providing accurate estimates of 
expression for the resulting clusters. We compare RapClust against a number of tools commonly 
used for de novo transcriptome clustering. Using de novo assemblies of organisms for which 
reference genomes are available, we assess the accuracy of these different methods in terms of 
the quality of the resulting clusterings, and the concordance of differential expression tests 
with those based on ground truth clusters. We find that RapClust produces clusters of comparable 
or better quality than existing state-of-the-art approaches, and does so substantially faster. 
RapClust also confers a large benefit in terms of space usage, as it produces only succinct 
intermediate files - usually on the order of a few megabytes - even when processing hundreds 
of millions of reads.

\subsection{Future Study}
\subsubsection{Selective Alignment ~\citep{selaln}}

Since its introduction in 2008~\citep{lister,nagalakshmi,mortazavi2008mapping}, transcriptome
profiling via RNA-seq has become a popular and widely-used technique to profile gene-
and transcript-level expression, and to identify and assemble novel transcripts.
Perhaps one of the most common uses of RNA-seq is to quantify gene expression,
often with the goal of subsequently performing differential expression analysis
on the gene abundance profiles. Due to improvements in RNA-seq quality and read
lengths, and also to significant improvements in the available quantification
methods, it has become increasingly common to perform quantification and
differential testing at the transcript level. Recently, there has been
considerable focus on developing very fast computational
methods~\citep{sailfish,kallisto,salmon,fleximer} for transcript abundance
estimation which obtain their speed, in part, by forgoing the traditional
prerequisite step of aligning the reads to the reference genome or
transcriptome. These methods have gained popularity due to their
markedly smaller computational requirements and their simplicity of use compared to more
traditional quantification ``pipelines'' that require alignment of the
sequencing reads to the genome or transcriptome, followed by the subsequent
processing of the resulting BAM file to obtain quantification estimates.

In various assessments on simulated data 
~\citep{kanitz2015comparative,germain2016rnaonthebench,zhang2017evaluation}, these lightweight 
methods have compared favorably to well-tested but much slower methods for
abundance estimation, like RSEM~\citep{li2011rsem} coupled with alignment methods such
as Bowtie2~\citep{bowtie2}. However, assessments based primarily (or entirely)
upon simulated data often fail to capture important aspects of real experiments,
and similar performance among methods on such simulated datasets does not
necessarily generalize to experimental data. Popular methods for transcript
quantification~\citep{rnaskim,fleximer,salmon,kallisto,sailfish,li2011rsem, heraem} 
differ in many aspects, ranging from how they handle read mapping
and alignment, to the optimization algorithms they employ, to subtle differences
in their generative models or which biases they model and correct for. These
differences are often obscured when analyzing simulated data, since aspects of
experimental data that can lead to substantial divergence in quantification
estimates are not properly recapitulated in simulation.

We focus on one aspect of abundance estimation, namely the
effect of read mapping on the resulting transcript quantification estimates. We
show that differences in how reads are aligned or mapped can lead to
considerable differences in the predicted abundances. Specifically, we find that
lightweight mapping approaches\citep{sailfish,kallisto,rapmap,fleximer}, which
are generally highly concordant with traditional alignment approaches in
simulated data, can lead to quite different abundance estimates from
alignment-based methods in experimental data. These differences happen
across a large number of samples, but the magnitude of the differences can vary 
substantially from sample to sample. 
We also find that these differences are independent of the optimization procedure used to
infer transcript abundances, and are instead a result of the different mapping and
alignment approaches returning distinct, and sometimes even disjoint, mapping loci
for certain reads.

It is somewhat difficult to categorically specify which approaches produce more accurate 
estimates in experimental data, due to the absence of a ground truth. However,
we argue that the divergence of lightweight mapping approaches from traditional
alignment is usually the result of a failure of the greedy heuristics adopted by
lightweight approaches, which are explicitly adopted to maximize the speed of
such methods.

This further explores and provides evidence for a hypothesis, raised
in~\citet{selaln} and ~\citet{heraem}, that lightweight-mapping approaches may suffer from
spurious mappings leading to a decrease in the resulting quantification
accuracy. We also demonstrate that, even among alignment-based approaches,
non-trivial differences arise between quantifications based upon mapping to the
transcriptome (using Bowtie2~\citep{bowtie2}) and quantifications based upon
mapping to the genome and subsequently projecting these alignments into
transcriptomic coordinates (using STAR~\citep{star}).

Finally, we plan to introduce an improved mapping algorithm, selective alignment (\hsa),
that is designed to remain fast, while simultaneously eliminating many of the
mapping errors made by lightweight approaches. Our proposed method increases
both the sensitivity and specificity of fast read mapping. It relies upon
alignment scoring to help differentiate between mapping loci that would
otherwise be indistinguishable due to, for example, similar exact matches along
the reference. Our approach also determines when even the best mapping for a
read exhibits insufficient evidence that the read truly originated from the
locus in question, allowing it to avoid spurious mappings. We benchmark this
approach on both simulated data and a broad collection of experimental
RNA-seq samples, and demonstrate that it leads to considerably improved
concordance with the abundance estimates obtained via quantification following
traditional alignment to the transcriptome.

\section{Single cell RNA-seq}
In ~\cref{alevin}, we present a new end-to-end pipeline for performing gene-level 
quantification from \dscrnaseq. We show that, compared to other methods, \alevin achieves
a higher accuracy, in part because of considering a substantially larger number
of reads. Further, \alevin is considerably faster and uses less memory than
these other approaches. The optimizations used in \alevin makes it possible to 
efficiently process \dscrnaseq datasets in a reduced computational burden for 
processing and re-processing of \dscrnaseq data.

\subsection{Supplementary Study}
\subsubsection{Swish ~\citep{zhu2019nonparametric}}
A primary challenge in the analysis of RNA-seq data is to identify differentially 
expressed genes or transcripts while controlling for technical biases present in 
the observations. Ideally, a statistical testing procedure should incorporate 
information about the inherent uncertainty of the abundance estimates, whether at 
the gene or transcript level, that arise from quantification of abundance. Most 
popular methods for RNA-seq differential expression analysis fit a parametric model 
to the counts or scaled counts for each gene or transcript, and a subset of methods 
can incorporate information about the uncertainty of the counts. Previous work has 
shown that nonparametric models for RNA-seq differential expression may in some cases 
have better control of the false discovery rate, and adapt well to new data types 
without requiring reformulation of a parametric model. Existing nonparametric models 
do not take into account the inferential uncertainty of the observations, leading to 
an inflated false discovery rate, in particular at the transcript level. Here we 
propose a nonparametric model for differential expression analysis using inferential 
replicate counts, extending the existing SAMseq method to account for inferential 
uncertainty, batch effects, and sample pairing. We compare our method, 
"SAMseq With Inferential Samples Helps", or Swish, with popular differential 
expression analysis methods. Swish has improved control of the false discovery rate, 
in particular for transcripts with high inferential uncertainty. We apply Swish to 
a single-cell RNA-seq dataset, assessing sensitivity to recover DE genes between 
sub-populations of cells, and compare its performance to the Wilcoxon rank sum test.

\subsubsection{Minnow (to appear in ISMB-2019)}
With the advancements of high-throughput single-cell RNA-sequencing protocols, there 
has been a rapid increase in the tools available to perform an array of analyses on the 
gene expression data that results from such studies.  For example, there exist methods 
for pseudo-time series analysis, differential cell usage ,cell-type detection RNA-velocity 
in single cells etc. Most analysis pipelines validate their results using known marker 
genes (which are not widely available for all types of analysis) and by using simulated 
data from gene-count-level simulators. Typically, the impact of using different 
read-alignment or UMI deduplication methods has not been widely explored. Assessments 
based on simulation tend to start at the level of assuming a simulated count matrix, 
ignoring the effect that different approaches for resolving UMI counts from the raw read 
data may produce. Here, we present minnow, a comprehensive sequence-level droplet-based 
single-cell RNA-seq (dscRNA-seq) experiment simulation framework.  Minnow accounts for 
important sequence-level characteristics of experimental scRNA-seq datasets and models 
effects such as PCR amplification,  CB (cellular barcodes) and UMI (Unique Molecule 
Identifiers) selection, and sequence fragmentation and sequencing. It also closely matches 
the gene-level ambiguity characteristics that are observed in real scRNA-seq experiments.  
Using minnow, we explore the performance of some common processing pipelines to produce 
gene-by-cell count matrices from droplet-bases scRNA-seq data, demonstrate the effect that 
realistic levels of gene-level sequence ambiguity can have on accurate quantification, 
and show a typical use-case of minnow in assessing the output generated by different 
quantification pipelines on the simulated experiment.

\subsection{Future Study}
\subsubsection{Alevin 2.0}
RNA-seq quantification has been shown as an important tool to explore the genome-wide
quantification of the gene expressions for both bulk and single cell RNA-seq experiments. 
Specially dscRNA-seq, recently, with the advancement in droplet based sequencing technologies 
~\citet{dropseq, indrop, tenx} is generating data with high quantitative accuracy, 
sensitivity and throughput. Previously, in ~\citep{alevin}, we have proposed a
principled approach for UMI deduplication of dscRNA-seq data which performs a maximum 
parsimony-based resolution of the PUGs (Parsimonious UMI Graph) and explore its advantage over 
traditional methods. 

While RNA-seq abundance estimation experiments capture only a static snapshot at a point in time, 
recent study (CITE) show for time-resolved phenomena such as embryogenesis a time derivative of 
the gene expression state -- RNA velocity -- can be estimated. [CITE et al] exploites the 
conclusions made on bulk experiments [CITE] that the balance between nascent (unspliced) and mature 
(spliced) mRNAs is predictive of cellular state progression and it can be modled to extrapolate the 
rate and direction of change in a dynamic biological processes. Specifically, they use the relative 
abundance of unspliced and spliced mRNA to model the rates of gene splicing and degradation in a
single cell experiment. Currently, \alevin does not model reads coming from an unspliced region as 
it works by aligning the reads to a reference transcriptome, where the sequence has pressumed to be 
from a spliced region. We plan to extend \alevin's UMI-deduplication model to include the reads 
aligning to unspliced regions of genome (we call unspliced reads) which, we believe, 
will further improve the quantification of dscRNA-seq data and the accuracy of tools consuming
the abundance estimates of the genes downstream.

The major challenges associated with incorporating unspliced reads into \alevin are two-fold.
Firstly, \alevin is internally driven by \salmon's framework of \rapmap based transcriptome 
alignment of RNA-seq reads; which restricts inclusion of unspliced reads into the reference 
as the transcriptome contains sequences, only, from the spliced region of a genome. 
Secondly, defining a principled approach to model the deduplication of the UMIs associated 
with unspliced reads, as the reads can also come from the spliced-unspliced region's boundary. 
One \naive approach is to separately include unspliced region of a genome into the reference 
transcriptome. However, in expectation the length of a unspliced region of a genome is much 
longer than that of a spliced region; which firstly makes the size of a \salmon index big, 
consuming more memory and secondly the difference in the length of the two regions can bias 
the parsimony resolution algorithm of \alevin towards the unspliced region, making this 
\naive approach unsuitable for practical use.

Although, salmon has pufferfish based sparse indexing scheme which can be used to reduce the 
size of the index, however, performing alignment based on pufferfish based indexing is 
still a work in progress. In this dissertation, we focus on the second challenge of modeling 
the deduplication of UMIs from unspliced region. We plan to use STAR, a spliced genome aligner, 
which has been used by many dscRNA-seq quantification pipeline as a default alignment method.
We plan to post process the alignments, as reported by STAR, and consume it downstream in
our proposed model of UMI deduplication. We discuss our proposed model in the following section.

\textbf{Model:} RNA-seq reads when aligned to reference genome can broadly be chategorized to 
align to either of 4 regions i.e. fully inside the spliced region (we call exonic unspliced read, EU), 
fully inside the unspliced region (intronic unspliced reads, IU),  from the boundary of two
exonic region (exon-exon boundary or Exon Spliced reads, ES) and lastly from the boundary of 
spliced-unspliced region (exon-intron boundary or Intron unspliced reads, IS). For our
model we consider IS, IU as essentially coming from intron (I) and considered the same.

We first categorize each mapped reads into one the three categories, namely, ES, EU and I.
Later, using the same notion as discussed in ~\Cref{alevin}, we further extend each node in the PUG 
to have an annotation (among ES, EU, I) along with the previous definition i.e. each node in the graph
had been represented by a tuple of the UMI sequences, the UMI counts and the transcript 
equivalence classes. One of the problem, with the previosuly discussed \naive approach of including 
unspliced region into the reference transcriptome, was that each node regardless of its annotation 
can be collapsed into other. In our new model, we restrict the PUG creation algorithm by constrainting 
the criteria for adding an edge (both bidirectional and unidrectional) i.e. we allow edges only between
annotation-compatible nodes. Compatibility among the three assignable categories can be defined as:
each category is compatible with itself and exon unspliced (EU) reads. Specifically, we disallow
edges between exon-spliced (ES) and Intron (I) aligned reads; restricting any one monochromatic
arborescence to cover two such nodes with these categories.

We believe that the proposed model has an added advantage of including, non trivial number of, reads
aligning to intronic region and utilizes information already present in the previously generated
dataset to improve the dscRNA-seq quantification, which otherwise would have been discarded.



























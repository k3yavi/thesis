% Chapter 1

\chapter{Conclusion and Future Work} % Main chapter title
\label{conclusion} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
% \newcommand{\keyword}[1]{\textbf{#1}}
% \newcommand{\tabhead}[1]{\textbf{#1}}
% \newcommand{\code}[1]{\texttt{#1}}
% \newcommand{\file}[1]{\texttt{\bfseries#1}}
% \newcommand{\option}[1]{\texttt{\itshape#1}}

In this dissertation, we have presented effective computational methods to improve the quantification 
of both bulk and dscRNA-seq data. In the following sections, we
give a brief overview of some of the supplementary work, which we have worked on;
along with the proposed future work.

\section{Bulk RNA-seq}

In ~\Cref{rapmap} we have discussed the usefulness of our novel approach, \qm, 
for mapping RNA-seq reads. We show our efficient implementation of \qm, in the 
form of \rapmap is fast, accurate and solves an important problem of read-mapping. 
In addition to that, we are reaching out to find other biological applications where 
\rapmap can be useful. In the following section, we discuss some of the applications, 
which we have worked on, or are currently working. 

\subsection{Supplementary Study}
\subsubsection{RapClust~\citep{srivastava2016accurate}}

De novo transcriptome assembly of non-model organisms is the first major step for many 
RNA-seq analysis tasks. Current methods for de novo assembly often report a large number 
of contiguous sequences (contigs), which may be fractured and incomplete sequences 
instead of full-length transcripts. Dealing with a large number of such contigs can 
slow and complicate downstream analysis. In this extension study, we present a method 
for clustering contigs from de novo transcriptome assemblies based upon the relationships 
exposed by multi-mapping sequencing fragments. Specifically, we cast the problem of 
clustering contigs as one of clustering a sparse graph that is induced by equivalence 
classes of fragments that map to subsets of the transcriptome. Leveraging recent developments 
in efficient read mapping and transcript quantification, we have developed RapClust, a tool 
implementing this approach that is capable of accurately clustering most large de novo 
transcriptomes in a matter of minutes, while simultaneously providing accurate estimates of 
expression for the resulting clusters. We compare RapClust against a number of tools commonly 
used for de novo transcriptome clustering. Using de novo assemblies of organisms for which 
reference genomes are available, we assess the accuracy of these different methods in terms of 
the quality of the resulting clusterings, and the concordance of differential expression tests 
with those based on ground truth clusters. We find that RapClust produces clusters of comparable 
or better quality than existing state-of-the-art approaches, and does so substantially faster. 
RapClust also confers a large benefit in terms of space usage, as it produces only succinct 
intermediate files - usually on the order of a few megabytes - even when processing hundreds 
of millions of reads.

\subsection{Future Study}
\subsubsection{Selective Alignment (2019 - ready with preprint)}

Since its introduction in 2008~\citep{lister,nagalakshmi,mortazavi2008mapping}, transcriptome
profiling via RNA-seq has become a popular and widely-used technique to profile gene-
and transcript-level expression, and to identify and assemble novel transcripts.
Perhaps one of the most common uses of RNA-seq is to quantify gene expression,
often with the goal of subsequently performing differential expression analysis
on the gene abundance profiles. Due to improvements in RNA-seq quality and read
lengths, and also to significant improvements in the available quantification
methods, it has become increasingly common to perform quantification and
differential testing at the transcript level. Recently, there has been
considerable focus on developing very fast computational
methods~\citep{sailfish,kallisto,salmon,fleximer} for transcript abundance
estimation which obtains their speed, in part, by forgoing the traditional
prerequisite step of aligning the reads to the reference genome or
transcriptome. These methods have gained popularity due to their
markedly smaller computational requirements and their simplicity of use compared to more
traditional quantification ``pipelines'' that require alignment of the
sequencing reads to the genome or transcriptome, followed by the subsequent
processing of the resulting BAM file to obtain quantification estimates.

In various assessments on simulated data 
~\citep{kanitz2015comparative,germain2016rnaonthebench,zhang2017evaluation}, these lightweight 
methods have compared favorably to well-tested but much slower methods for
abundance estimation, like RSEM~\citep{li2011rsem} coupled with alignment methods such
as Bowtie2~\citep{bowtie2}. However, assessments based primarily (or entirely)
upon simulated data often fail to capture important aspects of real experiments,
and similar performance among methods on such simulated datasets does not
necessarily generalize to experimental data. Popular methods for transcript
quantification~\citep{rnaskim,fleximer,salmon,kallisto,sailfish,li2011rsem, heraem} 
differ in many aspects, ranging from how they handle read mapping
and alignment, to the optimization algorithms they employ, to subtle differences
in their generative models or which biases they model and correct for. These
differences are often obscured when analyzing simulated data, since aspects of
experimental data that can lead to substantial divergence in quantification
estimates are not properly recapitulated in simulation.

We focus on the effect of read
mapping on the resulting transcript quantification estimates. To compare the
effect of different alignment and mapping methods in RNA-seq transcript
quantification and related downstream analysis we have picked tools from three
different categories of mapping strategies: unspliced alignment of RNA-seq reads
directly to the transcriptome, spliced alignment of RNA-seq reads to the
annotated genome (with subsequent projection to the transcriptome), and
(unspliced) lightweight mapping (\qm) of the RNA-seq reads directly to the
transcriptome. While numerous different lightweight mapping approaches
exist~\citep{sailfish,rnaskim,kallisto,rapmap,fleximer}, and the degree to
which they diverge from alignment-based methods can differ, a key feature
shared by such approaches is that they do not validate predicted fragment mappings
via an alignment score, which precludes them from discerning loci where the best mappings 
would not admit a reasonable-scoring alignment (i.e., spurious mappings). Furthermore, 
the focus on speed means that such methods tend not to explore sub-optimal mapping loci, 
despite the fact that such loci might admit the best alignment scores and therefore be 
the most likely origin for a fragment. We show that differences in how reads are aligned 
or mapped can lead to considerable differences in the predicted abundances. Specifically, we
find that lightweight mapping approaches, which are generally highly
concordant with traditional alignment approaches in simulated data, can lead to
quite different abundance estimates from alignment-based methods in experimental
data. These differences happen across a large number
of samples, but the magnitude of the differences can vary substantially from sample to sample. We
also find that these differences appear even when exactly the same optimization procedure
is used to infer transcript abundances, and are instead a result of the different
mapping and alignment approaches returning distinct, and sometimes even
disjoint, mapping loci for certain reads.

It is somewhat difficult to categorically specify which approaches produce more accurate 
estimates in experimental data, due to the absence of ground truth. However,
we argue that the divergence of lightweight mapping approaches from traditional
alignment is usually the result of a failure of the greedy heuristics adopted by
lightweight approaches, which are explicitly adopted to maximize the speed of
such methods. This further explores and provides evidence for a hypothesis, raised
in~\citet{selaln} and ~\citet{heraem}, that lightweight mapping approaches may suffer from
spurious mappings leading to a decrease in the resulting quantification
accuracy. We also demonstrate that, even among alignment-based approaches,
non-trivial differences arise between quantifications based upon mapping to the
transcriptome (using Bowtie2~\citep{bowtie2}) and quantifications based upon
mapping to the genome and subsequently projecting these alignments into
transcriptomic coordinates (using STAR~\citep{star}).

Finally, we introduce an improved mapping algorithm, selective alignment (\hsa),
that is designed to remain fast, while simultaneously eliminating many of the
mapping errors made by lightweight approaches. Our proposed method increases
both the sensitivity and specificity of fast read mapping. It relies upon
alignment scoring to help differentiate between mapping loci that would
otherwise be indistinguishable due to, for example, similar exact matches along with
the reference. Our approach also determines when even the best mapping for a
read exhibits insufficient evidence that the read truly originated from the
locus in question, allowing it to avoid spurious mappings. We benchmark this
approach on both simulated data and a broad collection of experimental
RNA-seq samples, and demonstrate that it leads to improved
concordance with the abundance estimates obtained via quantification following
traditional alignment to the transcriptome.

\section{Single cell RNA-seq}
In ~\cref{alevin}, we present a new end-to-end pipeline for performing gene-level 
quantification from \dscrnaseq. We show that, compared to other methods, \alevin achieves
 higher accuracy, in part because of considering a substantially larger number
of reads. Further, \alevin is considerably faster and uses less memory than
these other approaches. The optimizations used in \alevin makes it possible to 
efficiently process \dscrnaseq datasets in a reduced computational burden for 
processing and re-processing of \dscrnaseq data. In addition to that, we are reaching out to 
find other single cell platforms where \alevin can be useful. 
In the following section, we discuss some of the applications, which we have worked on, 
or are currently working.

\subsection{Supplementary Study}
\subsubsection{Swish ~\citep{zhu2019nonparametric}}
A primary challenge in the analysis of RNA-seq data is to identify differentially 
expressed genes or transcripts while controlling for technical biases present in 
the observations. Ideally, a statistical testing procedure should incorporate 
information about the inherent uncertainty of the abundance estimates, whether at 
the gene or transcript level, that arise from quantification of abundance. Most 
popular methods for RNA-seq differential expression analysis fit a parametric model 
to the counts or scaled counts for each gene or transcript, and a subset of methods 
can incorporate information about the uncertainty of the counts. Previous work has 
shown that nonparametric models for RNA-seq differential expression may in some cases 
have better control of the false discovery rate, and adapt well to new data types 
without requiring reformulation of a parametric model. Existing nonparametric models 
do not take into account the inferential uncertainty of the observations, leading to 
an inflated false discovery rate, in particular at the transcript level. Here we 
propose a nonparametric model for differential expression analysis using inferential 
replicate counts, extending the existing SAMseq method to account for inferential 
uncertainty, batch effects, and sample pairing. We compare our method, 
"SAMseq With Inferential Samples Helps", or Swish, with popular differential 
expression analysis methods. Swish has improved control of the false discovery rate, 
in particular for transcripts with high inferential uncertainty. We apply Swish to 
a single-cell RNA-seq dataset, assessing sensitivity to recover DE genes between 
sub-populations of cells, and compare its performance to the Wilcoxon rank sum test.

\subsubsection{Minnow (to appear in ISMB-2019)}
With the advancements of high-throughput single-cell RNA-sequencing protocols, there 
has been a rapid increase in the tools available to perform an array of analyses on the 
gene expression data that results from such studies.  For example, there exist methods 
for pseudo-time series analysis, differential cell usage ,cell-type detection RNA-velocity 
in single cells etc. Most analysis pipelines validate their results using known marker 
genes (which are not widely available for all types of analysis) and by using simulated 
data from gene-count-level simulators. Typically, the impact of using different 
read-alignment or UMI deduplication methods has not been widely explored. Assessments 
based on simulation tend to start at the level of assuming a simulated count matrix, 
ignoring the effect that different approaches for resolving UMI counts from the raw read 
data may produce. Here, we present minnow, a comprehensive sequence-level droplet-based 
single-cell RNA-seq (dscRNA-seq) experiment simulation framework.  Minnow accounts for 
important sequence-level characteristics of experimental scRNA-seq datasets and models 
effects such as PCR amplification,  CB (cellular barcodes) and UMI (Unique Molecule 
Identifiers) selection, and sequence fragmentation and sequencing. It also closely matches 
the gene-level ambiguity characteristics that are observed in real scRNA-seq experiments.  
Using minnow, we explore the performance of some common processing pipelines to produce 
gene-by-cell count matrices from droplet-bases scRNA-seq data, demonstrate the effect that 
realistic levels of gene-level sequence ambiguity can have on accurate quantification, 
and show a typical use-case of minnow in assessing the output generated by different 
quantification pipelines on the simulated experiment.

\subsection{Future Study}
\subsubsection{Alevin 2.0}
RNA-seq quantification has been shown as an important tool to explore the genome-wide
quantification of the gene expressions for both bulk and single cell RNA-seq experiments. 
Specially dscRNA-seq, recently with the advancement in droplet-based sequencing technologies 
~\citet{dropseq, indrop, tenx} is generating data with high quantitative accuracy, 
sensitivity, and throughput. In ~\Cref{alevin}, we have proposed a
principled approach for UMI deduplication of dscRNA-seq data which performs a maximum 
parsimony-based resolution of the PUGs (Parsimonious UMI Graph) and explore its advantage over 
traditional methods. 

While RNA-seq abundance estimation experiments capture only a static snapshot at a point in time, 
recent study ~\citep{la2018rna} show for time-resolved phenomena such as embryogenesis, a time derivative of 
the gene expression state -- RNA velocity -- can be estimated. ~\cite{la2018rna} exploits the 
conclusions made on bulk experiments ~\citep{zeisel2011coupled} that the balance between nascent (unspliced) and mature 
(spliced) mRNAs are predictive of cellular state progression and it can be modeled to extrapolate the 
rate and direction of change in dynamic biological processes. Specifically, they use the relative 
abundance of unspliced and spliced mRNA to model the rates of gene splicing and degradation in a
single cell experiment. We plan to extend \alevin's UMI-deduplication model to include the reads 
aligning to unspliced regions of the genome (we call unspliced reads) which, we believe, 
will further improve the quantification of dscRNA-seq data and the accuracy of tools consuming
the abundance estimates of the genes downstream.

The major challenges associated with incorporating unspliced reads into \alevin are two-fold.
Firstly, \alevin is internally driven by \salmon's framework of \rapmap based transcriptome 
alignment of RNA-seq reads; which restricts the inclusion of unspliced reads into the reference 
as the transcriptome contains sequences, only, from the spliced region of a genome. 
Secondly, defining a principled approach to model the deduplication of the UMIs associated 
with unspliced reads, as the reads can also come from the spliced-unspliced region's boundary. 
One \naive approach is to separately include the unspliced regions of a genome into the reference 
transcriptome. However, in expectation, the length of the unspliced region of a genome is much 
longer than that of a spliced region; which firstly makes the size of a \salmon index big, 
consuming more memory and secondly, the differences in the length of the two regions can bias 
the parsimony resolution algorithm of \alevin towards the unspliced region, making this 
\naive approach unsuitable for practical use.

Although, salmon has pufferfish based sparse indexing scheme which can be used to reduce the 
size of the index, however, performing alignment based on pufferfish based indexing is 
still a work in progress. In this dissertation, we focus on the second challenge of modeling 
the deduplication of UMIs from the unspliced region. We plan to use STAR, a spliced genome aligner, 
which has been used by many dscRNA-seq quantification pipelines as a default alignment method.
We plan to post-process the alignments, as reported by STAR, and consume it downstream in
our proposed model of UMI deduplication. We discuss our proposed model in the following section.

\textbf{Model:} RNA-seq reads when aligned to the reference genome can broadly be categorized to 
align to either of 4 regions i.e. fully inside one exonic region (we call exonic unspliced read, EU), 
fully inside one unspliced region (intronic unspliced reads, IU),  from the boundary of two
exonic region (exon-exon boundary or Exon Spliced reads, ES) and lastly from the boundary of 
spliced-unspliced region (exon-intron boundary or Intron unspliced reads, IS). For our
model IS, IU is considered the same and seen as coming from intron (I).

We first categorize each mapped reads into one the three categories, namely, ES, EU and I.
Later, using the same notion as discussed in ~\Cref{alevin}, we further extend each node in the PUG 
to have an annotation (among ES, EU, I) along with the previous definition of each node in the graph
being represented by a tuple of the UMI sequences, the UMI counts and the transcript 
equivalence classes. One of the problems with the previously discussed \naive approach of including 
unspliced region into the reference transcriptome was that each node regardless of its annotation 
can be collapsed into other. In our new model, we restrict the PUG creation algorithm by constraining 
the criteria for adding an edge (both bidirectional and unidirectional) i.e. we allow edges only between
annotation-compatible nodes. Compatibility among the three assignable categories can be defined as:
each category is compatible with itself and exon unspliced (EU) reads. Specifically, we disallow
edges between exon-spliced (ES) and Intron (I) aligned reads; restricting any one monochromatic
arborescence to cover two such nodes with these categories.

We believe that the proposed model has an added advantage of including, nontrivial number of, reads
aligning to the intronic region and utilizes information already present in the previously generated
dataset to improve the dscRNA-seq quantification, which otherwise would have been discarded.


























